{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.generators.random_graphs import random_regular_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from scipy.optimize import minimize\n",
    "from Unit import unit\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for generating data\n",
    "nodeList = {}\n",
    "\n",
    "Cscale = [[1.5, 3], [6, 2], [.8, .8]]\n",
    "Uscale = [[2.3, 1.1], [.9, 1.1], [2, 2]]\n",
    "tauA = {'intcp': -1, 'C0': .5, 'C1': .2, 'C2': .25, 'U0': .3, 'U1': -.2, 'U2': .25}\n",
    "tauM = {'intcp': -1, 'C0': -.3, 'C1': .4, 'C2': .1, 'A': 1, 'nborA': -.5, 'nborM': -1.5} #nborM 1.5\n",
    "tauY = {'intcp': -.3, 'nborA' : -1, 'M': 3, 'C0': -.2, 'C1': .2, 'C2': -.05, 'U0': .1, \n",
    "        'U1': -.2, 'U2': .25}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a networkx graph and store it to disk (call either this cell or the next cell BUT NOT BOTH)\n",
    "graph = random_regular_graph(3, 2000, seed=12345)\n",
    "with open('./2000_3/graph2000_3.pkl', 'wb') as fname:\n",
    "    pickle.dump(graph, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load a networkx graph from disk (call either this cell or the one preceding it BUT NOT BOTH)\n",
    "# with open('./800_3/graph800_3.pkl', 'rb') as fname:\n",
    "#     graph = pickle.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for sampling from the joint distribution p(M1, M2, ...)\n",
    "#Inputs: numIter - number of iterations to run the sampler, M - a dummy initialization matrix,\n",
    "#        tauM - parameters for M, nodeList - dictionary representation of the nodes in the graph (elements are Units; see Unit.py)\n",
    "#Output: M - a single sample from the joint p(M1, M2, ...)\n",
    "def Gibbs(numIter, M, tauM, nodeList):    \n",
    "        for k in range(1, numIter+1):\n",
    "            for i in range(len(nodeList)):\n",
    "                sumM = tauM['intcp'] + (tauM['C0'] * nodeList[i].C[0]) + (tauM['C1'] * nodeList[i].C[1])\n",
    "                sumM += (tauM['C2'] * nodeList[i].C[2])\n",
    "                sumM += (tauM['A'] * nodeList[i].A)\n",
    "\n",
    "                \n",
    "                for nbor in nodeList[i].adj:\n",
    "                    sumM += (tauM['nborA'] * nodeList[nbor].A) + (tauM['nborM'] * M[k-1, nbor])\n",
    "\n",
    "                Mi = np.random.binomial(1, expit(sumM))\n",
    "\n",
    "                M[k,i] = Mi\n",
    "\n",
    "        return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to perform an intervention in the network\n",
    "#Inputs: nodeList - dictionary representation of Units in graph, aVal - interventional value to set for A for ALL units in network\n",
    "#Output: nodeListIntervention - modified nodeList post-intervention (but not accounting for downstream effects)\n",
    "def doIntervention(nodeList, aVal):\n",
    "    nodeListIntervention = copy.deepcopy(nodeList)\n",
    "    for node in nodeListIntervention:\n",
    "        nodeListIntervention[node].A = aVal\n",
    "    return nodeListIntervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "-0.4562400000000005\n",
      "CPU times: user 7min 4s, sys: 1.28 s, total: 7min 5s\n",
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Y_GT = 0\n",
    "#perform ground truth calculations 5 times and calculate average effect to reduce effect of\n",
    "#differences between Gibbs sampler runs for calculating M's\n",
    "for iterations in range(5):\n",
    "    print(iterations)\n",
    "    Y_iter = 0\n",
    "    #generate data for C, U as in generateData.py\n",
    "    for node in graph.adj:\n",
    "        nodeList[node] = unit(np.zeros(3), np.zeros(3), graph.adj[node])\n",
    "        for j in range(len(Cscale)):\n",
    "            nodeList[node].C[j] = np.random.beta(Cscale[j][0], Cscale[j][1])\n",
    "            nodeList[node].U[j] = np.random.beta(Uscale[j][0], Uscale[j][1])\n",
    "    \n",
    "    #Perform interventions for A <- 1 and A <- 0\n",
    "    A1_NetEffect = doIntervention(nodeList, 1)\n",
    "    A0_NetEffect = doIntervention(nodeList, 0)\n",
    "\n",
    "    #Perform Gibbs sampling under intervention to get samples of M's\n",
    "    initMat1 = np.random.binomial(1, .5, (1051, len(nodeList)))\n",
    "    initMat0 = np.random.binomial(1, .5, (1051, len(nodeList)))\n",
    "    NetEffect1 = Gibbs(1050, initMat1, tauM, A1_NetEffect)\n",
    "    NetEffect0 = Gibbs(1050, initMat0, tauM, A0_NetEffect)\n",
    "\n",
    "    NetEffect1 = NetEffect1[1001:]\n",
    "    NetEffect1 = NetEffect1[::10,]\n",
    "    NetEffect0 = NetEffect0[1001:]\n",
    "    NetEffect0 = NetEffect0[::10,]\n",
    "    \n",
    "    #Extract 5 M samples from Gibbs and use these to calculate `Ground Truth' Y value including U as covariate\n",
    "    for i in range(len(nodeList)):\n",
    "        Yi = 0\n",
    "        \n",
    "        for j in range(5):\n",
    "            sumY1 = tauY['intcp'] + (tauY['M'] * NetEffect1[j, i]) + (tauY['C0'] * nodeList[i].C[0])\n",
    "            sumY1 += (tauY['C1'] * nodeList[i].C[1]) + (tauY['C2'] * nodeList[i].C[2]) + (tauY['U0'] * nodeList[i].U[0])\n",
    "            sumY1 += (tauY['U1'] * nodeList[i].U[1]) + (tauY['U2'] * nodeList[i].U[2])\n",
    "            for nbor in nodeList[i].adj:\n",
    "                sumY1 += (tauY['nborA'] * A1_NetEffect[nbor].A)\n",
    "            Y1 = np.random.binomial(1, expit(sumY1))\n",
    "\n",
    "            sumY0 = tauY['intcp'] + (tauY['M'] * NetEffect0[j, i]) + (tauY['C0'] * nodeList[i].C[0])\n",
    "            sumY0 += (tauY['C1'] * nodeList[i].C[1]) + (tauY['C2'] * nodeList[i].C[2]) + (tauY['U0'] * nodeList[i].U[0])\n",
    "            sumY0 += (tauY['U1'] * nodeList[i].U[1]) + (tauY['U2'] * nodeList[i].U[2])\n",
    "            for nbor in nodeList[i].adj:\n",
    "                sumY0 += (tauY['nborA'] * A0_NetEffect[nbor].A)\n",
    "            Y0 = np.random.binomial(1, expit(sumY0))\n",
    "            \n",
    "            Yi += Y1 - Y0\n",
    "        \n",
    "        #Average over 5 M samples\n",
    "        Y_iter += Yi / 5\n",
    "    \n",
    "    #Average across all nodes in network\n",
    "    Y_GT += Y_iter / len(nodeList)\n",
    "    \n",
    "#Average across 5 Gibbs runs\n",
    "Y_GT = Y_GT / 5\n",
    "print(Y_GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store ground truth effect to disk\n",
    "with open('./2000_3/groundTruth2000_3.pkl', 'wb') as fname:\n",
    "    pickle.dump(Y_GT, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
