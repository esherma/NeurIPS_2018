{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.generators.random_graphs import random_regular_graph\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from scipy.optimize import minimize\n",
    "from Unit import unit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import copy\n",
    "from DataGen import generateData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to estimate the parameters of M via the coding likelihood function\n",
    "#Inputs: tauM - parameters for M, S_max - listing of node IDs in maximal independent set,\n",
    "#        nodeList - dictionary representation of Units in graph\n",
    "#Output: likelihood value associated with tauM\n",
    "def codingLikelihoodM(tauM, S_max, nodeList):\n",
    "    total = 0\n",
    "    for i in S_max:\n",
    "        sumM = tauM[0] + (tauM[1] * nodeList[i].C[0]) + (tauM[2] * nodeList[i].C[1])\n",
    "        sumM += (tauM[3] * nodeList[i].C[2]) + (tauM[4] * nodeList[i].A)\n",
    "\n",
    "        for nbor in nodeList[i].adj:\n",
    "            sumM += (tauM[5] * nodeList[nbor].A) + (tauM[6] * nodeList[nbor].M)\n",
    "\n",
    "        if nodeList[i].M == 1:\n",
    "            total += np.log(expit(sumM))\n",
    "        else:\n",
    "            total += np.log(1 - expit(sumM))\n",
    "\n",
    "    return (-1 * total)\n",
    "\n",
    "#Function to estimate the parameters of M via the pseudo likelihood function\n",
    "#Inputs: tauM - parameters for M, S_max - listing of node IDs in maximal independent set,\n",
    "#        nodeList - dictionary representation of Units in graph\n",
    "#Output: likelihood value associated with tauM\n",
    "def pseudoLikelihoodM(tauM, nodeList):\n",
    "    total = 0\n",
    "    for i in nodeList:\n",
    "        sumM = tauM[0] + (tauM[1] * nodeList[i].C[0]) + (tauM[2] * nodeList[i].C[1])\n",
    "        sumM += (tauM[3] * nodeList[i].C[2]) + (tauM[4] * nodeList[i].A)\n",
    "\n",
    "        for nbor in nodeList[i].adj:\n",
    "            sumM += (tauM[5] * nodeList[nbor].A) + (tauM[6] * nodeList[nbor].M)\n",
    "\n",
    "        if nodeList[i].M == 1:\n",
    "            total += np.log(expit(sumM))\n",
    "        else:\n",
    "            total += np.log(1 - expit(sumM))\n",
    "\n",
    "    return (-1 * total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for sampling from the joint distribution p(M1, M2, ...)\n",
    "#Inputs: numIter - number of iterations to run the sampler, M - a dummy initialization matrix,\n",
    "#        tauM - parameters for M, nodeList - dictionary representation of the nodes in the graph (elements are Units; see Unit.py)\n",
    "#Output: M - a single sample from the joint p(M1, M2, ...)\n",
    "def Gibbs(numIter, M, tauM, nodeList):    \n",
    "        for k in range(1, numIter+1):\n",
    "            for i in range(len(nodeList)):\n",
    "                sumM = tauM['intcp'] + (tauM['C0'] * nodeList[i].C[0]) + (tauM['C1'] * nodeList[i].C[1])\n",
    "                sumM += (tauM['C2'] * nodeList[i].C[2])\n",
    "                sumM += (tauM['A'] * nodeList[i].A)\n",
    "\n",
    "                \n",
    "                for nbor in nodeList[i].adj:\n",
    "                    sumM += (tauM['nborA'] * nodeList[nbor].A) + (tauM['nborM'] * M[k-1, nbor])\n",
    "\n",
    "                Mi = np.random.binomial(1, expit(sumM))\n",
    "\n",
    "                M[k,i] = Mi\n",
    "\n",
    "        return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to perform an intervention in the network\n",
    "#Inputs: nodeList - dictionary representation of Units in graph, aVal - interventional value to set for A for ALL units in network\n",
    "#Output: nodeListIntervention - modified nodeList post-intervention (but not accounting for downstream effects)\n",
    "def doIntervention(nodeList, aVal):\n",
    "    nodeListIntervention = copy.deepcopy(nodeList)\n",
    "    for node in nodeListIntervention:\n",
    "        nodeListIntervention[node].A = aVal\n",
    "    return nodeListIntervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate causal effect estimates associated with interventions on A's in the network\n",
    "#Inputs: nodeList - dictionary representation of Units in graph, S_max - listing of node IDs in maximal independent set\n",
    "def getEstimates(nodeList, S_max):\n",
    "    #create initialized matrices for units' variables\n",
    "    As = np.zeros(len(nodeList))\n",
    "    nborAs = np.zeros((len(nodeList), len(nodeList[0].adj)))\n",
    "    Cs = np.zeros((len(nodeList), 3))\n",
    "    Ms = np.zeros(len(nodeList))\n",
    "    Ys = np.zeros(len(nodeList))\n",
    "\n",
    "    #Load data into nice, neat arrays\n",
    "    for node in nodeList:\n",
    "        As[node] = nodeList[node].A\n",
    "        idx = 0\n",
    "        for nbor in nodeList[node].adj:\n",
    "            nborAs[node, idx] = nodeList[nbor].A\n",
    "            idx += 1\n",
    "        Cs[node] = nodeList[node].C\n",
    "        Ms[node] = nodeList[node].M\n",
    "        Ys[node] = nodeList[node].Y\n",
    "\n",
    "    #Fit P(A|C) model\n",
    "    clfA = LogisticRegression()\n",
    "    clfA.fit(Cs, As)\n",
    "\n",
    "    #Fit P(Y|C, A, M) model\n",
    "    cov = np.concatenate((Cs, np.reshape(As, (As.shape[0], 1)), nborAs, np.reshape(Ms, (Ms.shape[0], 1))), axis=1)\n",
    "    clfY = LogisticRegression()\n",
    "    clfY.fit(cov, Ys)\n",
    "    \n",
    "    #Fit tauM via coding and pseudo likelihood estimation\n",
    "    tauM = np.random.rand(7)\n",
    "    codingM = minimize(codingLikelihoodM, tauM, (S_max, nodeList)).x\n",
    "    codingM = {'intcp': codingM[0], 'C0': codingM[1], 'C1': codingM[2], 'C2': codingM[3], 'A': codingM[4],\n",
    "               'nborA': codingM[5], 'nborM': codingM[6]}\n",
    "    pseudoM = minimize(pseudoLikelihoodM, tauM, (nodeList)).x\n",
    "    pseudoM = {'intcp': pseudoM[0], 'C0': pseudoM[1], 'C1': pseudoM[2], 'C2': pseudoM[3], 'A': pseudoM[4],\n",
    "               'nborA': pseudoM[5], 'nborM': pseudoM[6]}\n",
    "    \n",
    "    #[p(0|C), p(1|C)]\n",
    "    A1_NetEffect = doIntervention(nodeList, 1)\n",
    "    A0_NetEffect = doIntervention(nodeList, 0)\n",
    "\n",
    "    #Run Gibbs to obtain M's for each intervention\n",
    "    initMat1 = np.random.binomial(1, .5, (1051, len(nodeList)))\n",
    "    initMat0 = np.random.binomial(1, .5, (1051, len(nodeList)))\n",
    "    NetEffectCoding1 = Gibbs(1050, initMat1, codingM, A1_NetEffect)\n",
    "    NetEffectCoding0 = Gibbs(1050, initMat0, codingM, A0_NetEffect)\n",
    "\n",
    "    NetEffectCoding1 = NetEffectCoding1[1001:]\n",
    "    NetEffectCoding1 = NetEffectCoding1[::10,]\n",
    "    NetEffectCoding0 = NetEffectCoding0[1001:]\n",
    "    NetEffectCoding0 = NetEffectCoding0[::10,]\n",
    "    \n",
    "    initMat1 = np.random.binomial(1, .5, (1051, len(nodeList)))\n",
    "    initMat0 = np.random.binomial(1, .5, (1051, len(nodeList)))\n",
    "    NetEffectPseudo1 = Gibbs(1050, initMat1, pseudoM, A1_NetEffect)\n",
    "    NetEffectPseudo0 = Gibbs(1050, initMat0, pseudoM, A0_NetEffect)\n",
    "\n",
    "    NetEffectPseudo1 = NetEffectPseudo1[1001:]\n",
    "    NetEffectPseudo1 = NetEffectPseudo1[::10,]\n",
    "    NetEffectPseudo0 = NetEffectPseudo0[1001:]\n",
    "    NetEffectPseudo0 = NetEffectPseudo0[::10,]\n",
    "    \n",
    "    A_i_vals = [0,1]\n",
    "    Y_cod = 0\n",
    "    Y_pse = 0\n",
    "    \n",
    "    #Average over all nodes in graph\n",
    "    for i in range(len(nodeList)):\n",
    "        #Predict A given C\n",
    "        Acov = np.array([nodeList[i].C[0], nodeList[i].C[1], nodeList[i].C[2]])\n",
    "        Ahat = clfA.predict_proba(Acov.reshape(1,-1))\n",
    "        Yi_cod = 0\n",
    "        Yi_pse = 0\n",
    "        \n",
    "        #Predict Y 5 times for each intervention for coding likelihood to account for randomness in Gibbs process\n",
    "        for j in range(5):\n",
    "            for k in range(len(A_i_vals)):\n",
    "                Y1_cod_cov = np.array([nodeList[i].C[0], nodeList[i].C[1], nodeList[i].C[2], A_i_vals[k], 1, 1, 1, NetEffectCoding1[j, i]])\n",
    "                Y1_cod_hat = clfY.predict_proba(Y1_cod_cov.reshape(1,-1))\n",
    "                Y0_cod_cov = np.array([nodeList[i].C[0], nodeList[i].C[1], nodeList[i].C[2], A_i_vals[k], 0, 0, 0, NetEffectCoding0[j, i]])\n",
    "                Y0_cod_hat = clfY.predict_proba(Y0_cod_cov.reshape(1,-1))\n",
    "                Yi_cod += (Y1_cod_hat[0][1] * Ahat[0][k] - Y0_cod_hat[0][1] * Ahat[0][k])\n",
    "        #Average over the 5 Gibbs samples for Ms\n",
    "        Y_cod += Yi_cod / 5\n",
    "\n",
    "        #Predict Y 5 times for each intervention for pseudo likelihood to account for randomness in Gibbs process\n",
    "        for j in range(5):\n",
    "            for k in range(len(A_i_vals)):\n",
    "                Y1_pse_cov = np.array([nodeList[i].C[0], nodeList[i].C[1], nodeList[i].C[2], A_i_vals[k], 1, 1, 1, NetEffectPseudo1[j, i]])\n",
    "                Y1_pse_hat = clfY.predict_proba(Y1_pse_cov.reshape(1,-1))\n",
    "                Y0_pse_cov = np.array([nodeList[i].C[0], nodeList[i].C[1], nodeList[i].C[2], A_i_vals[k], 0, 0, 0, NetEffectPseudo0[j, i]])\n",
    "                Y0_pse_hat = clfY.predict_proba(Y0_pse_cov.reshape(1,-1))\n",
    "                Yi_pse += (Y1_pse_hat[0][1] * Ahat[0][k] - Y0_pse_hat[0][1] * Ahat[0][k])\n",
    "        #Average over the 5 Gibbs samples for Ms\n",
    "        Y_pse += Yi_pse / 5\n",
    "\n",
    "    #Average over all nodes in network\n",
    "    Y_cod = Y_cod / len(nodeList)\n",
    "    Y_pse = Y_pse / len(nodeList)\n",
    "    return Y_cod, Y_pse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a pre-created graph from disk\n",
    "with open('./2000_3/graph2000_3.pkl', 'rb') as fname:\n",
    "    graph = pickle.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate a maximal independent set of nodes in the network\n",
    "Xi = []\n",
    "lens = []\n",
    "for i in range(50):\n",
    "    Xi.append(nx.maximal_independent_set(graph))\n",
    "    lens.append(len(Xi[-1]))\n",
    "S_max = Xi[np.argmax(lens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nodeList = generateData(graph)\n",
    "estimates = getEstimates(nodeList, S_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
